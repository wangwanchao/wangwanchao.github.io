---
title: QUIC协议在Uber的实践(译)
date: 2020-09-06 10:09:01
tags:
categpries: NetWork
---
[原文](https://eng.uber.com/employing-quic-protocol/)

Uber对全球600多个城市的4500名手机用户做了调查，这些手机全部通过无线连接。为了实现实时的性能，App要求低延迟、高可用的网络通信。在动态的、损失率高的网络环境下，HTTP/2表现较差，最后我们追踪到性能差的主要原因还是基于系统实现的TCP比较差。
为了定位痛点，我们开始尝试使用QUIC协议，QUIC是一种基于UDP实现的流通信协议，我们可以更好的控制传输协议性能，现在已经被IETF采纳为HTTP/3协议标准。
在测试QUIC后，我们发现在App中整合QUIC相比原来的TCP可以降低末端延迟。可以确定在基于HTTPS的rider/driver apps中可以带来10-30%的延迟。除了在低延迟上的性能表现，QUIC提供了`packets流`端到端(end-to-end)的控制，这是基于用户空间层面的
<!-- more -->
## TCP 
在今天的网络中，TCP仍然是HTTPS通信中最广泛使用的通信协议。TCP提供了一种可信的字节流，解决了网络拥塞的复杂性、链路层丢失的问题。HTTPS广泛使用TCP主要还是因为TCP几乎存在于每一个保护TCP协议的系统中，例如负载均衡、HTTPS代理、CDNs，而且TCP在大多数平台、网络中都是开箱即用的。
我们的用户在使用Uber过程中位置是动态的，基于TCP的末端延迟很难满足HTTPS的实时特性。

### 基于无线网络的TCP
TCP最开始是为有线网络设计的，有高可预见的连接。然而无线网络有独特的特性和挑战。
1. 首先，由于干扰、信号衰减，无线网很容易丢失信号。这些都会导致RTTs更高或者变化、丢包。例如：WiFi很容易被微波、蓝牙、其他类型的信号波干扰。蜂窝网因为周围环境建筑物、干扰、附近基站的影响，很容易丢失信号
2. 为了在宽带和丢包中解决间歇的网络抖动问题，蜂窝网使用了更大的缓冲来接收突发流量。更大的buffer导致排队，结果是更长的延迟。由于超时，TCP通常把队列这种情况认为丢失，接着需要重传直到buffer继续被填满，这种问题称为缓存溢出`bufferbloat`。
3. 蜂窝网性能不同的用户、不同区域、不同时间也不一样。
**这个地方图片就不展示了，大家都体验过**
以上这些问题都归结于TCP的低效性，在深入理解TCP之前，我们先思考以下3个问题：
1. TCP是手机端用户末端延迟的主要原因吗？
2. 目前网络RTT、丢包是否变化很大？
3. 什么因素对TCP中RTT变化、丢包影响较大？

### TCP性能分析
为了更好地理解我们是怎么分析TCP性能的，首先简单介绍以下TCP通信过程：
1. 首先，发送端建立三次握手
2. 建立TLS连接：2-3个的round trips

![tcp](https://impwang.oss-cn-beijing.aliyuncs.com/net/tcp-1.png)
在这种情况下，packet丢失、或者ACK丢失，重传机制超时(RTO)后，发送端发起重传，RTO是根据不同的因素动态计算的：发送端和接收端的RTT估值。
为了分析TCP性能，我们使用tcpdump收集了印度市场一周内的网络连接情况，然后使用tcptrace进行了分析。除此之外，我们使用app发送请求到测试环境模拟了真实的情况，同时打印上传日志到服务器，然后部署到印度的应用市场。
无论是tapdump分析，还是日志分析，这两种分析结果都是一致的。RTT值、末端延迟几乎是中值的6倍，中值比平均值多1s。除此之外，包丢失严重，导致3.5%的重传率。在用户多的地方，丢失率甚至达到7%，例如火车站、机场。
相比数据包，对重传SYN、SYN-ACK包，TCP使用了非常保守的RTO值。大多数TCP都使用RTO=1s的初始值，随着包丢失的问题RTO以指数级增长。
数据包传输时，在无线网络下，更高的RTO导致网络可用时间更少。我们发现平均重传时间大约是1s，末端时间甚至可以达到30s，这种高延迟导致HTTPS超时、重试，从而导致更大的延迟，恶性循环。

## QUIC
基于QUIC的HTTP/2被定义为HTTP/3，她取代了HTTPS和TCP协议栈中的一些层，而且QUIC只支持安全数据传输，TLS协议被完全嵌套在QUIC协议中。
![QUIC](https://impwang.oss-cn-beijing.aliyuncs.com/net/quic-1.png)

以下就是为什么我们非常强烈的想要在TCP之外引入QUIC的特性：
1. 0-RTT建立连接。QUIC允许复用建立在之前连接上的安全认证，在第一个round trip过程就可以发送数据，减少了安全连接握手过程。未来，TLS1.3也会支持0-RTT，但是仍然需要TCP的三次握手。
2. 解决头阻塞问题。HTTP/2针对每个origin使用单个TCP连接来提升性能。但是会导致头阻塞(head-of-line blocking)问题。例如：object A被object B阻塞，A已经丢失，B需要等待A被恢复后进行传输。然而，QUIC每个请求的传输是独立的。
3. 拥塞控制。QUIC是应用层协议，可以更方便的更新核心算法，大多数TCP都使用CUBIC算法，这种算法不适用对延迟敏感的流量。最近开发的BBR算法，更精确，也优化了延迟。QUIC可以让我们随时启用BBR、更新核心算法。
4. 丢失恢复。在RTO被触发之前，即使很明显的丢失，QUIC仍然会发起2次丢失探针(TLP tail loss probes)，这种方式不同于TCP的实现。TLP重传丢失前最后的packet触发快速恢复机制。
5. 优化ACK机制。QUIC中每个packet都携带唯一的序列号，这就解决了区分重传包和延迟包的问题。ACK packet也包括了处理这个packet的时间、在客户端生成该packet的时间。这些因素可以确保QUIC更精确的估算RTT时间。QUIC ACK支持存储256个NACK，帮助发送端更好的执行packet重排序。TCP中的SACK(Selective ACK)没有解决这个问题。
6. 连接转移。QUIC连接是通过`connection ID`来标识的。不同于原来的四元组(源IP, 源Port, 目标IP, 目标Port)。这样，当客户端改变了IP地址后，请求不会中断，新的IP地址仍然可以使用旧的`connection ID`。对于移动端用户来说这是一种很常见的行为。

### QUIC选型的思考
在确定QUIC之前，我们调研了很多方案来提升TCP性能：
1. 首先，我们尝试了TCP PoPs(Points of Presence)。发现没有明显的性能提升。
2. 然后，我们尝试调整TCP参数。在异构服务系统中调整TCP协议栈参数是非常有挑战性的，而且TCP在跨系统 版本中有不同的实现。也很难应用、检验不同的配置。在用户端调整TCP配置更是几乎不可能。尤其像0-RTT这种协议设计的核心几乎不可能通过简单的调参实现提升。
3. 最后我们评估了一些基于UDP的协议查看是否对我们的应用有用。但是她们缺少工业级的安全特性。而QUIC兼顾了安全、性能。

### QUIC在Uber平台的整合


### QUIC在Google Cloud Load Balancers的开关
谷歌云负载均衡在response中添加了`alt-svc`头来支持QUIC。在每个HTTP response中，负载均衡组件都添加了`alt-svc`头验证是否支持QUIC，客户端收到携带`alt-svc`头的response后，接下来所有的HTTP请求使用QUIC。一旦负载均衡组件关闭了QUIC，则切换到HTTP2/TCP协议。

### 性能分析
性能是我们探索更好协议的首要因素，首先我们在不同的网络环境下进行了网络模拟来研究QUIC如何工作。为了验证QUIC在真实环境的性能收益，我们在公路上进行了仿真测试。
#### 阶段一


#### 阶段二

在第二阶段，我们遇到一些有趣的思考：


#### 生产阶段
受前面测试结果的鼓舞我们开始在Android和iOS中支持QUIC，我们在QUIC和TCP之间使用A/B测试来量化QUIC的性能。从不同的维度，我们看到了末端延迟显著的减少。


## 展望未来
在部署QUIC的过程中，无论是强网络还是弱网络，我们已经找到了几种方法来提升APP性能。
### 增加QUIC覆盖率
我们通过对真实场景的分析，大约80%的会话请求完全使用QUIC协议，大约15%的请求使用混合的TCP和QUIC。对于这种混合请求的场景，我们目前的猜想是：出现超时现象时，由于无法区分是UDP失败，还是弱网络环境，代码会自动切换到TCP协议。我们目前正在解决这个问题。

### QUIC优化
与占用带宽的应用相比，Uber应用对延迟比较敏感。而且我们的应用起初也是使用蜂窝网接入。以我们的经验来看，尽管使用QUIC替换TCP协议，末端延迟仍然非常高。我们团队仍然在探索新的方法来控制拥塞、提升丢失恢复算法来优化QUIC的延迟问题。

**翻译不好，有问题的地方多多反馈(邮箱：wwangwanchao@126.com)**